lapply(mtcars, function(x) x / mean(x))
lapply(mtcars, function(x) x / mean(x))
mtcars[] <- lapply(mtcars, function(x) x / mean(x))
xs <- runif(1e3)
res <- c()
for (x in xs){
res <- c(res, sqrt(x))
}
res <- numeric(length(xs))
res <- numeric(length(xs))
res <- numeric(length(xs))
for( i in seq_along(xs)){
res[i] <- sqrt(xs[i])
}
lapply(xs, function(x){})
lapply(seq_along(xs), function(i){})
lapply(names(xs), function(nm) {})
tmeans <- lapply(mtcars, mean)
mtmeans <- lapply(mtcars, mean)
mtmeans <- lapply(mtcars, mean)
mtmeans[] <- Map(`/`, mtcars, mtmeans)
Map(`/`, mtcars, mtmeans)
mtmeans <- lapply(mtcars, mean)
Map(`/`, mtcars, mtmeans)
x <- matrix(rnorm(20, 0, 10), nrow = 4)
x
sweep(x, 1, apply(x, 1, min), `-`)
outer(1:3, 1:10, "*")
outer(1:2, 1:10, "*")
outer(3:4, 1:10, "*")
outer(3:4, 9:10, "*")
library(plyr)
Reduce(`+`, 1:3)
Reduce(sum, 1:$)
Reduce(sum, 1:4)
l <- replicate(5, sample(1:10, 15, replace = T), simplify = FALSE)
l
Reduce(intersect, l)
class(1)
class(1.1)
class(1.00000000000000)
class(1.00000000000000)
showMethods(mean)
showMethods("mean")
methods("mean")
methods("lm")
methods("print")
methods("intersect")
library(roxygen2)
where <- function(f,x){
vapply(x, f, FUN.VALUE = logical(1), ...)
}
df <- data.frame(x = 1:3, y = c("a", "b", "c"))
df
where(is.factor, df)
where(is.factor, df)
where <- function(f,x){
vapply(x, f, FUN.VALUE = logical(1))
}
df <- data.frame(x = 1:3, y = c("a", "b", "c"))
where(is.factor, df)
str(Filter(is.factor, df))
Filter(is.numeric, df)
Filter(is.factor, df)
Find(is.factor, df)
Find(is.numeric, df)
Position(is.factor, df)
Position(is.numeric, df)
Position(is.na, df)
Position(is.data.frame, df)
poisson_nll <- function(x){
m <- length(x)
sum_x <- sum(x)
function(lambda){
n * lambda - sum_x * log(lambda)
}
}
x1 <- c(41, 30, 31, 38, 29, 24, 30, 29, 31, 38)
x2 <- c(6, 4, 7, 3, 3, 7, 5, 2, 2, 7, 5, 4, 12, 6, 9)
nll1 <- poisson_nll(x1)
nll2 <- poisson_nll(x2)
nll1
nll1()
optimise(nll1, c(0, 100))$minimum
optimise(nll1, c(0, 100))$minimum
x1 <- c(41, 30, 31, 38, 29, 24, 30, 29, 31, 38)
x2 <- c(6, 4, 7, 3, 3, 7, 5, 2, 2, 7, 5, 4, 12, 6, 9)
nll1 <- poisson_nll(x1)
nll2 <- poisson_nll(x2)
optimise(nll1, c(0, 100))$minimum
optimise(nll1, c(0, 100))$minimum
x1 <- c(41, 30, 31, 38, 29, 24, 30, 29, 31, 38)
x2 <- c(6, 4, 7, 3, 3, 7, 5, 2, 2, 7, 5, 4, 12, 6, 9)
nll1 <- poisson_nll(x1)
nll2 <- poisson_nll(x2)
optimise(nll1, c(0, 100))$minimum
poisson_nll <- function(x){
n <- length(x)
sum_x <- sum(x)
function(lambda){
n * lambda - sum_x * log(lambda)
}
}
x1 <- c(41, 30, 31, 38, 29, 24, 30, 29, 31, 38)
x2 <- c(6, 4, 7, 3, 3, 7, 5, 2, 2, 7, 5, 4, 12, 6, 9)
nll1 <- poisson_nll(x1)
nll2 <- poisson_nll(x2)
optimise(nll1, c(0, 100))$minimum
trans <- list(
disp = function(x) * 0.0163871,
trans <- list(
disp = function(x) x * 0.0163871,
am = function(x) factor(x, levels = c("auto", "manual"))
)
i <- 0
while(TRUE){
if (runif(1) > 0.9) break
i <- i + 1
}
while(TRUE){
if (runif(1) > 0.9) break
i <- i + 1
}
while(TRUE){
if (runif(1) > 0.9) break
i <- i + 1
}
while(TRUE){
if (runif(1) > 0.9) break
i <- i + 1
}
while(TRUE){
if (runif(1) > 0.9) break
i <- i + 1
}
while(TRUE){
if (runif(1) > 0.9) break
i <- i + 1
}
i
add <- function(x, y){
stopifnot(length(x) ==1, length(y)==1,
is.numeric(x), is.numeric(y))
x + y
}
add(1,10)
rm_na <- function(x, y, identity){
if(is.na(x) && is.na(y)){
identity
} else if( is.na(x)) {
y
} else {
x
}
}
rm_na(NA, 10 , 0)
rm_na(20, 10 , 0)
rm_na(20, 10 , 1-)
rm_na(20, 10 , 10)
rm_na(, 10 , 10)
rm_na(0, 10 , 10)
rm_n1 <- function() x, y, identical2){
if(is.na(x) && is.na(y)){
identitical2
} else if (is.na(x)){
y
} else{
x
rm_n1 <- function( x, y, identical2){
if(is.na(x) && is.na(y)){
identitical2
} else if (is.na(x)){
y
} else{
x
rm_n1 <- function( x, y, identical2){
if(is.na(x) && is.na(y)){
identitical2
} else if (is.na(x)){
y
} else{
x
}
}
add <- function(x, y, na.rm = FALSE){
if (na.rm && (is.na(x) || is.na(y)))
rm_na(x,y,0)
else x + y
}
add(10,NA)
Reduce(sum, 1:3)
r_add <- function(xs, na.rm = TRUE){
Reduce(function(x, y) add(x, y, na.rm = na.rm), xs)
}
download.file("http://gecon.r-forge.r-project.org/models/SW_03/SW_03.gcn",
destfile = "SW_03.gcn")
sw_gecon1 <- make_model('SW_03.gcn')
library(gEcon)
library(dplyr)
library(tidyr)
install.packages("gECON")
library(arules)
library(shiny)
library(DT)
# As of 24-April-2015, this example librarys a development version of
# the networkD3 package available from:
# devtools::install_github("bwlewis/networkD3")
library(networkD3)
data(Adult)
shiny::runApp(list(
ui = pageWithSidebar( # See ?pageWithSidebar for help
headerPanel("Association Rules Explorer"),
sidebarPanel(
sliderInput("support", div(HTML("support")), min=0.005, max=0.99, value=0.5, step=0.001),
sliderInput("conf", div(HTML("confidence")), min=0.1, max=0.99, value=0.9, step=0.01),
sliderInput("minlen", "minimum rule length", min=1, max=5, value=2, step=1),
sliderInput("maxlen", "max rule length", min=2, max=6, value=6, step=1),
sliderInput("maxrules", "max rules to display", min=50, ,max=250, value=100, step=10),
p("The arules::Adult database was extracted from the census bureau database
found at http://www.census.gov/ftp/pub/DES/www/welcome.html
in 1994 by Ronny Kohavi and Barry Becker, Data Mining and
Visualization, Silicon Graphics. It was originally used to predict
whether income exceeds USD 50K/yr based on census data.")
),
mainPanel(
simpleNetworkOutput("graph"),
textOutput("notes"),
DT::dataTableOutput('tbl')
)
),
server = function(input, output, session)
{
arules = reactive({
rules = apriori(Adult, parameter=list(
supp=input$support,
conf=input$conf,
minlen=input$minlen,
maxlen=input$maxlen, target="rules"))
if(length(rules)<1) stop("No rules found, try decreasing support or confidence values.")
i = order(rules@quality$lift, decreasing=TRUE)[1:min(input$maxrules,length(rules))]
rules[i]
})
output$graph = renderSimpleNetwork(
{
rules = arules()
# Color edges by lift value
fl = factor(rules@quality$lift)
edge_colors = substr(rainbow(length(levels(fl)), start=0,end=1/6),1,7)
edges=data.frame(source=as.factor(labels(lhs(rules))$elements), target= as.factor(labels(rhs(rules))$elements))
simpleNetwork(edges, directed=TRUE,linkColour=edge_colors, fontSize=12, textColour="#000099", height=1000,charge=-2000)
})
output$tbl = DT::renderDataTable({
rules = arules()
DT::datatable(data.frame(lhs=labels(lhs(rules))$elements,
rhs=labels(rhs(rules))$elements,
support=signif(rules@quality$support,4),
confidence=signif(rules@quality$confidence,4),
lift=signif(rules@quality$lift,4)))
})
output$notes = renderText({
rules = arules()
if(length(rules)==0)
{
sprintf("No rules found. Try lowering support, minlen or confidence values.")
} else {
sprintf("Displaying top %d of %d rules found, ranked by lift.", min(length(rules),input$maxrules), length(rules))
}
})
}
))
devtools::install_github(c("dcenergy/rflot"))
getwd()
setwd("Z:/Ferguson 13 march/other assignment/DS/Coursera/Courses/Developing Data Products/testApp")
library(shiny)
runApp()
runApp()
runApp()
education <- read.csv("Z:/Ferguson 13 march/other assignment/DS/Coursera/Courses/Developing Data Products/testApp/district.csv")
education <- read.csv("Z:/Ferguson 13 march/other assignment/DS/Coursera/Courses/Developing Data Products/testApp/district.csv")
runApp()
View(education)
runApp()
runApp()
runApp()
print(ggplot(dataset, aes(x = percentage, y = gender)) +
geom_point())
print(ggplot(education, aes(x = percentage, y = gender)) +
geom_point())
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
education[education$district =="larkana",]
unique(education[education$district =="larkana",])
runApp()
library(plotly)
library(plotly)
runApp()
runApp()
runApp()
unique(education$factor)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
library(slidify)
library(slidifyLibraries)
serwd("Z:/Ferguson 13 march/other assignment/DS/Coursera/Courses/Developing Data Products/Slidify Presentation")
setwd("Z:/Ferguson 13 march/other assignment/DS/Coursera/Courses/Developing Data Products/Slidify Presentation")
author("DDP-Azam")
setwd("~/")
setwd("Z:\Ferguson 13 march\other assignment\DS\Coursera\Courses\Developing Data Products\Slidify Presentation")
setwd("Z:/Ferguson 13 march/other assignment/DS/Coursera/Courses/Developing Data Products/Slidify Presentation")
library(rdatamarket)
library(astsa)
paper <- dmseries("http://data.is/Ur24KI")
#-------Data Section begins--------
plot(paper, type="o", ylab="Sales",main="Industry Sales for Printing and Writing Paper")
#plot(paper,type="o", ylim=c(0,1200), xlab=" ",ylab=" ")
#par(new=TRUE)
#plot(SMA(paper), col=2,ylim=c(0,1200), xlab="Index",
#     ylab="Car Sales", main="Moving Average Plot for Car Sales (in red)")
plot(diff(paper,12), type="o")
plot(diff(diff(paper,12)), type="o", ylab="Paper Sales",main="Monthly Industry Sales for Printing and Writing Paper")
#-------Model Section begins--------
n = length(paper)
n # 120
train.size = round(n*0.95)
train.size # 114
train.data = paper[1:114]
test.data = paper[115:120]
paper.transformed = diff(diff(train.data, 12)) # on train.data
# acf(paper.transformed, 48)
# pacf(paper.transformed, 48)
acf2(paper.transformed, 48)
#---
P=4
Q=4
crit<-matrix(0,P+1,Q+1)
for (j in 0:P)
{
for (k in 0:Q)
{
dataML<-arima(train.data,order=c(j,1,k),seasonal=list(order=c(0,1,1),period=12),method="ML")
#AICC
crit[j+1,k+1]<-n*log(dataML$sigma)+2*(j+k+1)*n/(n-j-k-2)
#BIC
#crit[j+1,k+1]<-n*log(dataML$sigma)+(j+k+1)*log(n)
#AIC
#crit[j+1,k+1]<-n*log(dataML$sigma)+2*(j+k+1)
}
}
#locate the minimum information criteria
crit
min(crit)
# BIC&AICc
sarima(train.data, 0,1,1,0,1,1,12)
bic.pr=sarima.for(train.data,6,0,1,1,0,1,1,12)
bic.pr
lines(paper[114:120],type="o")
# AIC
sarima(train.data, 2,1,3,0,1,1,12)
aic.pr=sarima.for(train.data,6,2,1,3,0,1,1,12)
aic.pr
lines(paper[114:120],type="o")
# forcast errors
#pred=bic.pr$pred
pred = aic.pr$pred
fe=rep(0,6)
for(i in 1:6)
{
fe[i]<-(pred[i]-test.data[i])^2
}
fe
sum(fe)
#-----spectral density analysis begins--------
data=diff(diff(paper,12))
T=108
freq<-(1:(T/2))/T
per<-(abs(fft(data)))^2/T
per<-per[2:(T/2+1)]
truespec<-spec.pgram(data, taper=0, log="no")
Umax<-max(max(truespec$spec),max(per))
plot(freq,per,type="l",ylab="spectral density",ylim=c(0,Umax))
lines(freq,truespec$spec,ylim=c(0,Umax),col=2,lwd=3)
#par(mfrow=c(2,2))
k1 = kernel("modified.daniell", c(1,1))
truespec1<-spec.pgram(data, kernel =k1,taper=0, log="no")
per.ave1 = spec.pgram(data, kernel =k1, taper=0, log ="no",plot=F)$spec
plot(freq,per,type="o",ylab="spectral density",ylim=c(0,Umax))
lines(freq,truespec1$spec,ylim=c(0,Umax),col=2,lwd=3)
k2 = kernel("modified.daniell", c(2,2))
truespec2<-spec.pgram(data, kernel =k2,taper=0, log="no")
per.ave2 = spec.pgram(data, kernel =k2, taper=0, log ="no",plot=F)$spec
plot(freq,per.ave2,type="l",ylab="spectral density",ylim=c(0,Umax))
lines(freq,truespec2$spec,ylim=c(0,Umax),col=2,lwd=3)
k2 = kernel("modified.daniell", c(2,2))
truespec2<-spec.pgram(data, kernel =k2,taper=0, log="no")
k3 = kernel("modified.daniell", c(3,3))
truespec3<-spec.pgram(data, kernel =k3,taper=0, log="no")
k4 = kernel("modified.daniell", c(4,4))
truespec4<-spec.pgram(data, kernel =k4,taper=0, log="no")
Umax<-max(max(truespec$spec),max(per))
#abline(v=1/12, lty="dotted")
k2 = kernel("modified.daniell", c(2,2))
per.ave2 = spec.pgram(data, kernel =k2, taper=0, log ="no",plot=F)$spec
plot(freq,truespec$spec,type="l",col=1,lwd=3)
lines(freq,per.ave2,col=2,lwd=3,type="l")
slidify("index.Rmd")
getwd()
setwd("Z:/Ferguson 13 march/other assignment/DS/Coursera/Courses/Developing Data Products/Slidify Presentation/DDP-Azam")
slidify("index.Rmd")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
load("C:/Users/MP14/Downloads/unnamed-chunk-1_c920266eba512af5166fa48befb88e3c (1).RData")
slidify("index.Rmd")
browseURL("index.html")
getwd()
slidify("index.Rmd")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
getwd()
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
getwd()
setwd("Z:/Ferguson 13 march/other assignment/DS/Coursera/Courses/Developing Data Products/Slidify Presentation/DDP-Azam/assets/img")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
slidify("index.Rmd")
setwd("Z:/Ferguson 13 march/other assignment/DS/Coursera/Courses/Developing Data Products/Slidify Presentation/DDP-Azam")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
publish("AzamYahya", "DDP")
publish_github("DDP")
slidify("index.Rmd")
browseURL("index.html")
library(shinyapps)
deployApp()
setwd("Z:/Ferguson 13 march/other assignment/DS/Coursera/Courses/Developing Data Products/testApp")
deployApp()
devtools::install_github('rstudio/packrat')
deployApp()
deployApp()
runApp()
deployApp()
deployApp(appDir = "Z:/Ferguson 13 march/other assignment/DS/Coursera/Courses/Developing Data Products/testApp/rsconnect/shinyapps.io/azam")
deployApp()
